_base_: "default.yml"
data:
  batch_size: 64
  dataset:
    train:
      - gcc3m
      - gcc12m

model:
  type: TCL
  clip_model: ViT-B/16  # NOTE only ViT-based backbones are supported.
  ie_freeze: 11  # index [1 ~ 12]
  ie_ignore_last_attn: true  # use MaskCLIP
  masker:
    type: Masker
    decoder:
      type: GDecoder
      double: true
      n_layers: 2
      kernel_size: 3
      act: gelu
      norm: ln
    sim2mask:
      init_w: 10.0
      init_b: -2.5
      gumbel_tau: 1.0
      learnable: true

  # tcl
  tcl_w: 0.1
  area_w: 0.4

  # total variation
  tv_w: 1.0

train:
  total_steps: 50000
  warmup_steps: 15000
  ust_steps: 30000  # train decoder only in this steps
  base_lr: 3e-4
  weight_decay: 0.05
  min_lr: 4e-5
  clip_grad: 5.0
  optimizer:
    eps: 1e-6

evaluate:
  pamr: true
  bg_thresh: 0.4
  kp_w: 0.3

  eval_freq: 5000
  template: custom
  task:
    - t_voc20
    - t_context59

checkpoint:
  save_topk: 0

model_name: "release"
